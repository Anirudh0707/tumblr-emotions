\begin{thebibliography}{6}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Bengio \& LeCun(2007)Bengio and LeCun]{Bengio+chapter2007}
Yoshua Bengio and Yann LeCun.
\newblock Scaling learning algorithms towards {AI}.
\newblock In \emph{Large Scale Kernel Machines}. MIT Press, 2007.

\bibitem[Bollen et~al.(2011)Bollen, Mao, and Zeng]{Bollen}
Johan Bollen, Huina Mao, and Xiao-Jun Zeng.
\newblock Twitter mood predicts the stock market.
\newblock \emph{Journal of Computational Science}, 2:\penalty0 1--8, 2011.

\bibitem[Flaxman \& Kassam(2016)Flaxman and Kassam]{Seth-16}
Seth Flaxman and Karim Kassam.
\newblock On \#agony and \#ecstasy: Potential and pitfalls of linguistic
  sentiment analysis.
\newblock In preparation, 2016.

\bibitem[Hinton et~al.(2006)Hinton, Osindero, and Teh]{Hinton06}
Geoffrey~E. Hinton, Simon Osindero, and Yee~Whye Teh.
\newblock A fast learning algorithm for deep belief nets.
\newblock \emph{Neural Computation}, 18:\penalty0 1527--1554, 2006.

\bibitem[Mikolov et~al.(2013)Mikolov, Chen, Corrado, and Dean]{Mikolov-13}
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.
\newblock Efficient estimation of word representations in vector space.
\newblock In \emph{ICLR}, 2013.

\bibitem[Szegedy et~al.(2015)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{Szegedy-15}
Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir
  Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
\newblock Going deeper with convolutions.
\newblock In \emph{CVPR}, 2015.

\end{thebibliography}
