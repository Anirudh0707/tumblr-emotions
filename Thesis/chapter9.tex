\chapter{Conclusions}

Deep Sentiment infers the emotional state of Tumblr users with high accuracy by combining textual and visual information.

On images, fine-tuning the Inception network managed to extract useful features at a reduced computational cost as convolutional neural networks are known to be tedious to train. On text, projecting words into a high-dimensional space added semantic understanding of the words that could be effectively used in the recurrent layer to capture the meaning of the sentences. 

The synergy between text and image is quite formidable given the jump in accuracy: from about 40-60\% to 90\%. At a larger scale, this algorithm could be applied population wise in order to have a real-time emotion trend during important events for example.

Deep Sentiment can also be rearranged to generate new Tumblr text matching a given emotion. Changing the model to instead accept characters instead of words could make the model better learn the specific way of writing in blogs.

Likewise, we could try to make the model learn to generate an image given a few blog sentences. The network would try to create an image that most closely matches the text it was given.

Lastly, an interesting experiment to make would be to try to manually label Tumblr posts in order to know whether Deep Sentiment beats human performance.


