\chapter{Conclusions}

Deep Sentiment is able to determine the emotional state of Tumblr users with high accuracy by combining the textual and visual information.

On images, fine-tuning the Inception network managed to extract useful features at a reduced computational cost as convolutional neural networks are known to be tedious to train. On text, projecting words into a high dimensional space added semantic understanding of the words that could be effectively used in the recurrent layer to capture the meaning of the sentences. 

The synergy between text and image is quite formidable given the jump in accuracy: from about 40-60\% to 90\%. At a larger scale, this algorithm could be applied population wise in order to have a real-time emotion trend during important events for example.

The deep neural network can also be rearranged to generate brand new Tumblr text according to a given emotion. Changing the model to instead accept characters instead of words could better learn the specific way of writing in blogs.

Likewise, we could try to make the model learn to generate an image given a few blog sentences. The network would try to create the image that most closely match the text it was given. For instance, a post talking about engagement and rings could produce an image with hands with engagement rings.

Lastly, an interesting experiment to make would be to try to manually label Tumblr posts in order to assess whether Deep Sentiment beats human performance.


