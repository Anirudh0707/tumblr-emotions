\chapter{Introduction}

Sentiment analysis has been an active area of research in the past few years, especially on the readily available Twitter data, e.g. Bollen et al. \cite{bollen} who investigated the impact of collective mood states on stock market or Flaxman et al. \cite{seth-twitter} who analysed day-of-week population well-being.

Contrary to Twitter, Tumblr's posts are not limited to 140 characters, allowing more expressiveness, and are not centered on the textual content but on the image content instead. A Tumblr post will almost always be an image with some text accompanying the latter. Pictures have become prevalent on social media and characterising them could enable the understanding of billions of users. 

We propose a novel method to uncover the emotional state of an individual posting on social media. The ground truth emotion will be extracted from the tags, considered as the `self-reported' emotion of the user. Our model incorporates both text and image and we aim to `read' them to be able to understand the emotional content they imply about the user. Concretely, the Deep Sentiment model associates the features learned by the two modalities as follows:

\begin{itemize}
    \item We fine-tune a pre-trained Deep Convolutional Neural Network, named Inception \cite{googlenet}, trained on the ImageNet dataset to our specific task of emotion inferring.
    \item We project the text in a rich high-dimensional space with a word representation learned by Word2Vec \cite{word2vec}, that was trained on billions of words. The word vectors then go through a Recurrent Neural Network which preserves the word order and captures the semantics of human language.
    \item A fully-connected layer combines the information in the two modalities and a final softmax output layer gives the probability distribution of the emotional state of the user.
\end{itemize}

We will also see that Deep Sentiment can be rearranged to generate Tumblr posts expressing one of the learned emotion.









