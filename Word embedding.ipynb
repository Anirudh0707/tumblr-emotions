{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from text_model.text_embedding import compute_sklearn_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#for i in range(30):\n",
    "    #index = np.random.randint(df_all.shape[0])\n",
    "    #print(df_all['search_query'][index])\n",
    "    #print(df_all['text'][index])\n",
    "    #print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading word embedding weights.\n",
      "Finished loading dataframes.\n",
      "Computing sklearn features:\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "X_sklearn, y_sklearn = compute_sklearn_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(295424, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sklearn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_RANDOM_SEED = 0\n",
    "X_sklearn_train, X_sklearn_valid, y_sklearn_train, y_sklearn_valid = train_test_split(X_sklearn, y_sklearn, \n",
    "                                                                                      test_size=0.2,\n",
    "                                                                                      random_state=_RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.519279509518\n",
      "0.517864094102\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_sklearn_train, y_sklearn_train)\n",
    "print(accuracy_score(logreg.predict(X_sklearn_train), y_sklearn_train))\n",
    "print(accuracy_score(logreg.predict(X_sklearn_valid), y_sklearn_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.582438784966\n",
      "0.511043412034\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(max_depth=12)\n",
    "forest.fit(X_sklearn_train, y_sklearn_train)\n",
    "print(accuracy_score(forest.predict(X_sklearn_train), y_sklearn_train))\n",
    "print(accuracy_score(forest.predict(X_sklearn_valid), y_sklearn_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading word embedding weights.\n",
      "Finished loading dataframes.\n",
      "Training:\n"
     ]
    }
   ],
   "source": [
    "from text_model.text_embedding import main\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Epoch: 10\n",
    "0%  loss = 1.150, accuracy = 0.555, speed = 430 pps\n",
    "10%  loss = 1.061, accuracy = 0.593, speed = 5735 pps\n",
    "20%  loss = 1.063, accuracy = 0.590, speed = 5972 pps\n",
    "30%  loss = 1.065, accuracy = 0.589, speed = 6057 pps\n",
    "40%  loss = 1.064, accuracy = 0.589, speed = 6093 pps\n",
    "50%  loss = 1.064, accuracy = 0.589, speed = 6116 pps\n",
    "60%  loss = 1.063, accuracy = 0.589, speed = 6122 pps\n",
    "70%  loss = 1.063, accuracy = 0.589, speed = 6135 pps\n",
    "80%  loss = 1.062, accuracy = 0.589, speed = 6145 pps\n",
    "90%  loss = 1.063, accuracy = 0.589, speed = 6145 pps\n",
    "100%  loss = 1.063, accuracy = 0.589, speed = 6150 pps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading word embedding weights.\n"
     ]
    }
   ],
   "source": [
    "from datasets.download_images import download_im_with_text\n",
    "\n",
    "search_query = 'surprised'\n",
    "start = 0\n",
    "end = 100\n",
    "download_im_with_text(search_query, start, end, dataset_dir='data', subdir='photos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading word embedding weights.\n",
      ">> Converting image 215/215 shard 4\n",
      ">> Converting image 50/50 shard 4\n",
      "\n",
      "Finished converting the dataset!\n"
     ]
    }
   ],
   "source": [
    "from datasets.convert_images_tfrecords import convert_images_with_text\n",
    "\n",
    "# num_valid=4000 right now\n",
    "convert_images_with_text('data', num_valid=50, photos_subdir='photos', tfrecords_subdir='tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From image_model/im_model.py:200: softmax_cross_entropy (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.softmax_cross_entropy instead.\n",
      "WARNING:tensorflow:From //anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:394: compute_weighted_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.compute_weighted_loss instead.\n",
      "WARNING:tensorflow:From //anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:151: add_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.add_loss instead.\n",
      "WARNING:tensorflow:From image_model/im_model.py:201: get_total_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_total_loss instead.\n",
      "WARNING:tensorflow:From //anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:261: get_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_losses instead.\n",
      "WARNING:tensorflow:From //anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py:263: get_regularization_losses (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.\n",
      "Instructions for updating:\n",
      "Use tf.losses.get_regularization_losses instead.\n",
      "INFO:tensorflow:Starting Session.\n",
      "INFO:tensorflow:Starting Queues.\n",
      "INFO:tensorflow:global_step/sec: 0\n",
      "INFO:tensorflow:global step 1: loss = 2.5072 (23.67 sec/step)\n",
      "INFO:tensorflow:global step 2: loss = 2.4847 (14.01 sec/step)\n",
      "INFO:tensorflow:global step 3: loss = 2.5421 (13.79 sec/step)\n",
      "INFO:tensorflow:global_step/sec: 0.0503884\n",
      "INFO:tensorflow:global step 4: loss = 2.5466 (20.87 sec/step)\n",
      "INFO:tensorflow:global step 5: loss = 2.7608 (15.83 sec/step)\n",
      "INFO:tensorflow:Stopping Training.\n",
      "INFO:tensorflow:Finished training! Saving model to disk.\n",
      "Finished training. Last batch loss 2.761\n"
     ]
    }
   ],
   "source": [
    "from image_model.im_model import fine_tune_model_with_text\n",
    "\n",
    "dataset_dir = 'data'\n",
    "checkpoints_dir = 'image_model/pretrained_model'\n",
    "train_dir = 'image_model/fine_tuned_model'\n",
    "num_steps = 5\n",
    "learning_rate = 1e-7\n",
    "fine_tune_model_with_text(dataset_dir, checkpoints_dir, train_dir,\n",
    "                          num_steps, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.py:298: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "INFO:tensorflow:Waiting for new checkpoint at image_model/fine_tuned_model\n",
      "INFO:tensorflow:Found new checkpoint at image_model/fine_tuned_model/model.ckpt-5\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-02-11:58:26\n",
      "INFO:tensorflow:Evaluation [1/5]\n",
      "INFO:tensorflow:Evaluation [2/5]\n",
      "INFO:tensorflow:Evaluation [3/5]\n",
      "INFO:tensorflow:Evaluation [4/5]\n",
      "INFO:tensorflow:Evaluation [5/5]\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-02-11:58:49\n",
      "INFO:tensorflow:Waiting for new checkpoint at image_model/fine_tuned_model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b8a6ea54b9ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnum_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mevaluate_model_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_evals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/hu/Documents/tumblr-sentiment/image_model/im_model.py\u001b[0m in \u001b[0;36mevaluate_model_2\u001b[0;34m(checkpoint_dir, log_dir, mode, num_evals)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mnum_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             eval_op=names_to_updates.values())\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoftmax_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/evaluation.pyc\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(master, checkpoint_dir, logdir, num_evals, initial_op, initial_op_feed_dict, eval_op, eval_op_feed_dict, final_op, final_op_feed_dict, summary_op, summary_op_feed_dict, variables_to_restore, eval_interval_secs, max_number_of_evaluations, session_config, timeout)\u001b[0m\n\u001b[1;32m    283\u001b[0m       \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m       \u001b[0mmax_number_of_evaluations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_number_of_evaluations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m       timeout=timeout)\n\u001b[0m",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.pyc\u001b[0m in \u001b[0;36mevaluate_repeatedly\u001b[0;34m(checkpoint_dir, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, eval_interval_secs, hooks, config, max_number_of_evaluations, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m   \u001b[0mnum_evaluations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m   for checkpoint_path in checkpoints_iterator(checkpoint_dir,\n\u001b[0;32m--> 523\u001b[0;31m                                               eval_interval_secs, timeout):\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     session_creator = monitored_session.ChiefSessionCreator(\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.pyc\u001b[0m in \u001b[0;36mcheckpoints_iterator\u001b[0;34m(checkpoint_dir, min_interval_secs, timeout)\u001b[0m\n\u001b[1;32m    217\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     checkpoint_path = wait_for_new_checkpoint(\n\u001b[0;32m--> 219\u001b[0;31m         checkpoint_dir, checkpoint_path, timeout=timeout)\n\u001b[0m\u001b[1;32m    220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;31m# timed out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.pyc\u001b[0m in \u001b[0;36mwait_for_new_checkpoint\u001b[0;34m(checkpoint_dir, last_checkpoint, seconds_to_sleep, timeout)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mstop_time\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mseconds_to_sleep\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstop_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds_to_sleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found new checkpoint at %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from image_model.im_model import evaluate_model_2\n",
    "\n",
    "checkpoint_dir = 'image_model/fine_tuned_model'\n",
    "log_dir = 'image_model/model_eval'\n",
    "mode = 'train'\n",
    "num_evals = 5\n",
    "        \n",
    "evaluate_model_2(checkpoint_dir, log_dir, mode, num_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/39732460/how-to-use-evaluation-loop-with-train-loop-in-tf-slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.py:298: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\n",
      "INFO:tensorflow:Waiting for new checkpoint at image_model/fine_tuned_model\n",
      "INFO:tensorflow:Found new checkpoint at image_model/fine_tuned_model/model.ckpt-5\n",
      "INFO:tensorflow:Starting evaluation at 2017-09-02-11:59:33\n",
      "INFO:tensorflow:Evaluation [1/5]\n",
      "INFO:tensorflow:Evaluation [2/5]\n",
      "INFO:tensorflow:Evaluation [3/5]\n",
      "INFO:tensorflow:Evaluation [4/5]\n",
      "INFO:tensorflow:Evaluation [5/5]\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-02-11:59:55\n",
      "INFO:tensorflow:Waiting for new checkpoint at image_model/fine_tuned_model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6dbb51893bd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnum_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mevaluate_model_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_evals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/hu/Documents/tumblr-sentiment/image_model/im_model.py\u001b[0m in \u001b[0;36mevaluate_model_2\u001b[0;34m(checkpoint_dir, log_dir, mode, num_evals)\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mnum_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_evals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m             eval_op=names_to_updates.values())\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoftmax_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/slim/python/slim/evaluation.pyc\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(master, checkpoint_dir, logdir, num_evals, initial_op, initial_op_feed_dict, eval_op, eval_op_feed_dict, final_op, final_op_feed_dict, summary_op, summary_op_feed_dict, variables_to_restore, eval_interval_secs, max_number_of_evaluations, session_config, timeout)\u001b[0m\n\u001b[1;32m    283\u001b[0m       \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m       \u001b[0mmax_number_of_evaluations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_number_of_evaluations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m       timeout=timeout)\n\u001b[0m",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.pyc\u001b[0m in \u001b[0;36mevaluate_repeatedly\u001b[0;34m(checkpoint_dir, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, eval_interval_secs, hooks, config, max_number_of_evaluations, timeout)\u001b[0m\n\u001b[1;32m    521\u001b[0m   \u001b[0mnum_evaluations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m   for checkpoint_path in checkpoints_iterator(checkpoint_dir,\n\u001b[0;32m--> 523\u001b[0;31m                                               eval_interval_secs, timeout):\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     session_creator = monitored_session.ChiefSessionCreator(\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.pyc\u001b[0m in \u001b[0;36mcheckpoints_iterator\u001b[0;34m(checkpoint_dir, min_interval_secs, timeout)\u001b[0m\n\u001b[1;32m    217\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     checkpoint_path = wait_for_new_checkpoint(\n\u001b[0;32m--> 219\u001b[0;31m         checkpoint_dir, checkpoint_path, timeout=timeout)\n\u001b[0m\u001b[1;32m    220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;31m# timed out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/training/python/training/evaluation.pyc\u001b[0m in \u001b[0;36mwait_for_new_checkpoint\u001b[0;34m(checkpoint_dir, last_checkpoint, seconds_to_sleep, timeout)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mstop_time\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mseconds_to_sleep\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstop_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds_to_sleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found new checkpoint at %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from image_model.im_model import evaluate_model_2\n",
    "\n",
    "checkpoint_dir = 'image_model/fine_tuned_model'\n",
    "log_dir = 'image_model/model_eval'\n",
    "mode = 'validation'\n",
    "num_evals = 5\n",
    "        \n",
    "evaluate_model_2(checkpoint_dir, log_dir, mode, num_evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
